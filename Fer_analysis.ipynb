{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Fer_analysis.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJhR0Bl6SSqY",
        "outputId": "97145136-55bb-4ebe-c31d-761ac00b253a"
      },
      "source": [
        "!pip install mtcnn"
      ],
      "id": "dJhR0Bl6SSqY",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.19.5)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58ec6e0e-dd49-431f-9a02-828fd7fd3944"
      },
      "source": [
        "#import math\n",
        "import os\n",
        "import imutils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv2\n",
        "import glob\n",
        "#import csv\n",
        "#from sklearn import datasets\n",
        "#from sklearn.multiclass import OneVsRestClassifier\n",
        "#from sklearn.svm import LinearSVC\n",
        "#from sklearn.model_selection import KFold\n",
        "#from sklearn.metrics import confusion_matrix,classification_report\n",
        "#from sklearn.metrics import roc_curve, auc\n",
        "#from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "#from itertools import cycle\n",
        "#from scipy import interp\n",
        "#from sklearn.multiclass import OneVsRestClassifier\n",
        "#import random\n",
        "#from scipy import ndarray\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "#from skimage import util\n",
        "#from sklearn.svm import SVC\n",
        "#from skimage import io\n",
        "import copy\n",
        "from mtcnn.mtcnn import MTCNN \n",
        "from skimage import feature"
      ],
      "id": "58ec6e0e-dd49-431f-9a02-828fd7fd3944",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7HK1RxiSOJv",
        "outputId": "8d89bdd1-4072-48f7-9b95-d0471003ae24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\",force_remount=True)"
      ],
      "id": "O7HK1RxiSOJv",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a59eea2-850d-4537-8b90-776da0ce1467"
      },
      "source": [
        "## Data collection"
      ],
      "id": "6a59eea2-850d-4537-8b90-776da0ce1467"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac0a1e5a-dc0f-44b3-8873-355b47476058"
      },
      "source": [
        "def _process_row( row ):\n",
        "    \"\"\"\n",
        "    Process a single dataframe row, returns the argmax label\n",
        "    :param row:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    return np.argmax( row )"
      ],
      "id": "ac0a1e5a-dc0f-44b3-8873-355b47476058",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a177d5a-5f50-4f52-8a28-ac32b5146866"
      },
      "source": [
        "main_path = '/content/drive/MyDrive/FER/Data/Images'\n",
        "train_path = os.path.join( main_path, 'FER2013Train' )\n",
        "test_path = os.path.join( main_path, 'FER2013Test' )\n",
        "valid_path = os.path.join( main_path, 'FER2013Valid' )\n",
        "\n",
        "#initialize dataframe FER+ with actuall images in folder (some might be missing or duplicates)\n",
        "def get_DataFrame( path_name ):\n",
        "    label_file = os.path.join(path_name, 'label.csv')\n",
        "    data_df = pd.read_csv(label_file, header=None)\n",
        "    data_df.columns = [\"img_name\", \"dims\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\",\"Unknown\", \"NF\"]\n",
        "    data_df['actual_label'] = data_df[['0', '1', '2', '3', '4', '5', '6', '7']].apply(lambda x: _process_row(x), axis=1)\n",
        "\n",
        "    # get all ilocs with actual label 0\n",
        "    data_df = data_df.sort_values(by=['img_name'])\n",
        "    image_file_names = data_df['img_name'].values\n",
        "    d_files = [ filename.split('/')[-1] for filename in glob.glob(path_name+'/*.*') ]\n",
        "    data_df['exist_file'] = [ 1 if ii in d_files else np.nan for ii in image_file_names ]\n",
        "    return data_df.dropna()\n",
        "\n",
        "#reads image in cv2 format, transforms to grayscale since many operations needs this\n",
        "def get_Image( path ):\n",
        "    return cv2.imread( path, cv2.IMREAD_GRAYSCALE )\n",
        "\n",
        "#converts gray image to string\n",
        "def _grayimg2string( img ):\n",
        "    return str(img.flatten().tolist()).replace(']','').replace('[','')\n",
        "\n",
        "#converts string to gray image\n",
        "def _string2grayimage( img, size=(48,48) ):\n",
        "    return np.array(img.split(', ')).astype(np.uint8).reshape( size )\n",
        "\n",
        "\n",
        "#creates dataframes per emotion loading images in gray scale\n",
        "def get_emotionsDataFrames( path_name, data_df ):\n",
        "    for ii in data_df['actual_label'].unique():\n",
        "        dd = data_df[data_df['actual_label']==ii][['img_name','actual_label']]\n",
        "        dd['img_str'] = dd['img_name'].apply(lambda x: _grayimg2string( get_Image( path_name+'/'+x ) ) )\n",
        "        dd.to_csv(path_name+'/'+f'labels_{ii}.csv', index=False)\n",
        "    return        "
      ],
      "id": "6a177d5a-5f50-4f52-8a28-ac32b5146866",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc48d9a2-337d-4741-b6df-ab12d9e85c09"
      },
      "source": [
        "get_emotionsDataFrames( train_path, get_DataFrame( train_path ) )\n",
        "get_emotionsDataFrames( test_path, get_DataFrame( test_path ) )\n",
        "get_emotionsDataFrames( valid_path, get_DataFrame( valid_path ) )"
      ],
      "id": "fc48d9a2-337d-4741-b6df-ab12d9e85c09",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8a1bad3-c75f-4b85-a185-2a56e25c06b4"
      },
      "source": [
        "## Data cleaning"
      ],
      "id": "c8a1bad3-c75f-4b85-a185-2a56e25c06b4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f18d3862-c14a-432b-a379-a7d168a22a22"
      },
      "source": [
        "#For plotting image\n",
        "def show( img ):\n",
        "    plt.imshow( img, cmap='gray' )\n",
        "    return\n",
        "\n",
        "#Cleaning noise\n",
        "def Denoising( img, h=10, templateWindowSize=7, searchWindowSize=21 ):\n",
        "    return cv2.fastNlMeansDenoising(img,None,h,templateWindowSize,searchWindowSize)"
      ],
      "id": "f18d3862-c14a-432b-a379-a7d168a22a22",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17cd7789-b6c3-4db2-b34a-7baeb94a7d31"
      },
      "source": [
        "#detect faces with mtcnn\n",
        "# we use this library after reading https://towardsdatascience.com/face-detection-models-which-to-use-and-why-d263e82c302c \n",
        "def ReturnLocalizedFace( img ):\n",
        "    detector = MTCNN()\n",
        "    faces = detector.detect_faces( cv2.cvtColor( img, cv2.COLOR_GRAY2RGB ) )\n",
        "    return faces\n",
        "\n",
        "#draw faces result from mtcnn (https://towardsdatascience.com/face-detection-using-mtcnn-a-guide-for-face-extraction-with-a-focus-on-speed-c6d59f82d49)\n",
        "def DrawFacesMTCNN( img, faces ):\n",
        "    plt.imshow( img, cmap='gray' )\n",
        "    ax = plt.gca()\n",
        "    for face in faces:\n",
        "        x, y, w, h = face['box']\n",
        "        rect = plt.Rectangle( (x,y), w, h , fill=False, color='green', lw=1 )\n",
        "        ax.add_patch( rect )\n",
        "        for key, value in face['keypoints'].items():\n",
        "            dot = plt.Circle( value, radius=3, color='red' )\n",
        "            ax.add_patch( dot )\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "#detect faces and uses eye-eye position to rotates and match a given \"standard\" \n",
        "def RotatetoFrontalFace( img, faces ):\n",
        "    #target positions from image FER2013Test/fer0032232.png\n",
        "    le_t = np.array([13,18],dtype=float)\n",
        "    re_t = np.array([35,18],dtype=float)\n",
        "    no_t = np.array([24,30],dtype=float)\n",
        "    ml_t = np.array([17,41],dtype=float)\n",
        "    mr_t = np.array([31,41],dtype=float)\n",
        "    eye_separation = re_t[0]-le_t[0]\n",
        "    \n",
        "    #faces = ReturnLocalizedFace( img )\n",
        "    if len(faces)!=1:\n",
        "        return None\n",
        "    \n",
        "    le=faces[0].get('keypoints').get('left_eye')\n",
        "    if not le:\n",
        "        return None\n",
        "    le=np.array(le,dtype=float)\n",
        "    re=faces[0].get('keypoints').get('right_eye')\n",
        "    if not re:\n",
        "        return None    \n",
        "    re=np.array(re,dtype=float)\n",
        "    \n",
        "    lr = re - le\n",
        "    lr_n = np.linalg.norm(lr)\n",
        "    c_alph = lr[0]/lr_n\n",
        "    sgn = np.sign(lr[1])\n",
        "    s_alph = sgn*np.sqrt(1-c_alph**2)\n",
        "    scale = eye_separation/lr_n\n",
        "    \n",
        "    rot_mat = np.array([[  scale*c_alph,  scale*s_alph,  -scale*c_alph*le[0]+le_t[0]-scale*s_alph*le[1] ],\n",
        "                      [ -scale*s_alph,  scale*c_alph,  -scale*c_alph*le[1]+le_t[1]+scale*s_alph*le[0] ]])\n",
        "    \n",
        "    new_img = cv2.warpAffine( img, rot_mat)\n",
        "    #return crop image in size of \"standard\"\n",
        "    return new_img[0:48, 0:48]"
      ],
      "id": "17cd7789-b6c3-4db2-b34a-7baeb94a7d31",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0584b04-6855-42e3-be72-95e13efa02b8"
      },
      "source": [
        "## Feature extraction\n",
        "Here we assume that:\n",
        "1. A an image **img** was read with  **get_Image** (or loaded from new dataframes, ie 'labels_0.csv')\n",
        "2. Then **img = Denoising( img )**\n",
        "3. **faces = ReturnLocalizedFace( img )** \n",
        "4. **img = RotatetoFrontalFace( img, faces )** \n",
        "before extracting features."
      ],
      "id": "e0584b04-6855-42e3-be72-95e13efa02b8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55703201-7d64-40e4-bc36-7ba943629c0d"
      },
      "source": [
        "#Extracts HOG\n",
        "def ExtractHOG( img, win_size=(64,128) ):    \n",
        "    img = cv2.resize( img, win_size )\n",
        "    #hog\n",
        "    d = cv2.HOGDescriptor()\n",
        "    hog = d.compute( img )\n",
        "    return hog\n",
        "    \n",
        "#Extract Gabor \n",
        "# based on https://cvtuts.wordpress.com/2014/04/27/gabor-filters-a-practical-overview/\n",
        "# TODO (change to frequency domain as in https://www.ini.rub.de/upload/file/1470692845_33efbf50567f9d637771/LadEtAl1993.pdf\n",
        "#        and file:///tmp/mozilla_gabriel0/ICCV2005-ZhangShan-LGBP.pdf)\n",
        "def BuildGaborFilters( ksize=11, sigma=3, lambd=9, gamma=0.5, psi=0. ):\n",
        "    filters0=[]\n",
        "    filters1=[]\n",
        "    for theta in np.arange( 0, np.pi, np.pi/8 ):\n",
        "        kern0 = cv2.getGaborKernel( (ksize,ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n",
        "        kern0 /= 1.5*kern0.sum()\n",
        "        kern1 = cv2.getGaborKernel( (ksize,ksize), sigma/np.sqrt(2), theta, lambd/np.sqrt(2), gamma, psi, ktype=cv2.CV_32F)\n",
        "        kern1 /= 1.5*kern0.sum()\n",
        "        filters0.append(kern0)\n",
        "        filters1.append(kern1)\n",
        "    \n",
        "    return filters0, filters1\n",
        "\n",
        "filters = BuildGaborFilters()\n",
        "\n",
        "def ProcessGabor( img, filters ):\n",
        "    accum0 = np.zeros_like(img)\n",
        "    accum1 = np.zeros_like(img)\n",
        "    for kern0 in filters[0]:\n",
        "        fimg = cv2.filter2D( img, cv2.CV_8UC3, kern0 )\n",
        "        np.maximum( accum0, fimg, accum0 )\n",
        "    for kern1 in filters[1]:\n",
        "        fimg = cv2.filter2D( img, cv2.CV_8UC3, kern1 )\n",
        "        np.maximum( accum1, fimg, accum1 )    \n",
        "    \n",
        "    return accum0, accum1\n",
        "    \n",
        "#Extract LBP Features \n",
        "# divides in 7X7 squares as in https://www.pyimagesearch.com/2021/05/03/face-recognition-with-local-binary-patterns-lbps-and-opencv/\n",
        "# class based in https://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/\n",
        "\n",
        "# ALTERNATIVE (use overlaping planes as in Figure 1 of http://www.scholarpedia.org/article/Local_Binary_Patterns\n",
        "#      ref https://d1wqtxts1xzle7.cloudfront.net/39765451/Dynamic_Texture_Recognition_Using_Local_20151106-14680-19lgjsz-with-cover-page-v2.pdf?Expires=1636851787&Signature=F00Aon5sbz1RCybxye5lrG~AV~Xw6DTPn79CRtsNGJMNSKWb8~JkkIRA9~9FtNnO8AgumGrhfoGq1VJHlUbGCkQb9incCas-7kZlrtFLJCsu3R~d114P2vkphi-TkqKdwvgpre9s6WMynHBgseCrMT9vEvP38uz3a4BC16qrUaP~BENzgD-HbSW88VlGaGfrToapU-tP-dDGR6k5j2ctjz-y3anfa2qronHqgUa4p7HgJUdnKhYQzm3fSj01A~r5y0EzoL3OqTNNRl8Uxezu-9V~acDYT4AQvl3KiAbQRNxmnRfYbhOFwJo3lMppdUuyYmQi7MPHZGvnrQMT8Z07YA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA \n",
        "#      )\n",
        "class LocalBinaryPatterns:\n",
        "    def __init__( self, numPoints, radius):\n",
        "        self.numPoints = numPoints\n",
        "        self.radius = radius\n",
        "        \n",
        "    def describe(self, image, eps=1e-7):    \n",
        "        lbp = feature.local_binary_pattern(image, self.numPoints, self.radius, method=\"uniform\")\n",
        "        (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, self.numPoints + 3),\n",
        "            range=(0, self.numPoints + 2))\n",
        "        # normalize the histogram\n",
        "        hist = hist.astype(\"float\")\n",
        "        hist /= (hist.sum() + eps)\n",
        "        # return the histogram of Local Binary Patterns\n",
        "        return hist\n",
        "\n",
        "LBPdesc = LocalBinaryPatterns(8, 1)\n",
        "\n",
        "def ExtractLBPHist( img, LBPdesc ):\n",
        "    LBP = []\n",
        "    for ii in range(0,7):\n",
        "        for jj in range(0,7):\n",
        "            hist = LBPdesc.describe( img[ ii*7:(ii+1)*7, jj*7:(jj+1)*7 ] )\n",
        "            LBP.append(hist)\n",
        "    return LBP"
      ],
      "id": "55703201-7d64-40e4-bc36-7ba943629c0d",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz-l3SM-Ab-V"
      },
      "source": [
        ""
      ],
      "id": "Oz-l3SM-Ab-V",
      "execution_count": null,
      "outputs": []
    }
  ]
}